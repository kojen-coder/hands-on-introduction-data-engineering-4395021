[[34m2024-09-29T05:02:02.588+0000[0m] {[34mscheduler_job_runner.py:[0m788} INFO[0m - Starting the scheduler[0m
[[34m2024-09-29T05:02:02.589+0000[0m] {[34mscheduler_job_runner.py:[0m795} INFO[0m - Processing each file at most -1 times[0m
[[34m2024-09-29T05:02:02.594+0000[0m] {[34mmanager.py:[0m165} INFO[0m - Launched DagFileProcessorManager with pid: 25430[0m
[[34m2024-09-29T05:02:02.595+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-09-29T05:02:02.598+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2024-09-29T05:02:02.617+0000] {manager.py:411} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-09-29T05:07:02.753+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-09-29T05:12:03.302+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-09-29T05:13:27.901+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: one_task_dag.one_task manual__2024-09-29T05:13:25.327104+00:00 [scheduled]>[0m
[[34m2024-09-29T05:13:27.901+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG one_task_dag has 0/16 running and queued tasks[0m
[[34m2024-09-29T05:13:27.901+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: one_task_dag.one_task manual__2024-09-29T05:13:25.327104+00:00 [scheduled]>[0m
[[34m2024-09-29T05:13:27.903+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='one_task_dag', task_id='one_task', run_id='manual__2024-09-29T05:13:25.327104+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-09-29T05:13:27.904+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'one_task_dag', 'one_task', 'manual__2024-09-29T05:13:25.327104+00:00', '--local', '--subdir', 'DAGS_FOLDER/one_task_dag.py'][0m
[[34m2024-09-29T05:13:27.954+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'one_task_dag', 'one_task', 'manual__2024-09-29T05:13:25.327104+00:00', '--local', '--subdir', 'DAGS_FOLDER/one_task_dag.py'][0m
[[34m2024-09-29T05:13:28.768+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/one_task_dag.py[0m
[[34m2024-09-29T05:13:29.239+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: one_task_dag.one_task manual__2024-09-29T05:13:25.327104+00:00 [queued]> on host codespaces-c567e2[0m
[[34m2024-09-29T05:13:30.096+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='one_task_dag', task_id='one_task', run_id='manual__2024-09-29T05:13:25.327104+00:00', try_number=1, map_index=-1)[0m
[[34m2024-09-29T05:13:30.102+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=one_task_dag, task_id=one_task, run_id=manual__2024-09-29T05:13:25.327104+00:00, map_index=-1, run_start_date=2024-09-29 05:13:29.324045+00:00, run_end_date=2024-09-29 05:13:29.760875+00:00, run_duration=0.43683, state=success, executor_state=success, try_number=1, max_tries=0, job_id=4, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-09-29 05:13:27.902420+00:00, queued_by_job_id=3, pid=30313[0m
[[34m2024-09-29T05:13:30.188+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun one_task_dag @ 2024-09-29 05:13:25.327104+00:00: manual__2024-09-29T05:13:25.327104+00:00, state:running, queued_at: 2024-09-29 05:13:25.403305+00:00. externally triggered: True> successful[0m
[[34m2024-09-29T05:13:30.189+0000[0m] {[34mdagrun.py:[0m681} INFO[0m - DagRun Finished: dag_id=one_task_dag, execution_date=2024-09-29 05:13:25.327104+00:00, run_id=manual__2024-09-29T05:13:25.327104+00:00, run_start_date=2024-09-29 05:13:26.224848+00:00, run_end_date=2024-09-29 05:13:30.189274+00:00, run_duration=3.964426, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-09-29 05:13:25.327104+00:00, data_interval_end=2024-09-29 05:13:25.327104+00:00, dag_hash=3e1b820a4adcc81953d03899ce23f9da[0m
[[34m2024-09-29T05:17:03.329+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-09-29T05:22:03.874+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-09-29T05:24:40.417+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: two_task_dag.bash_task_0 manual__2024-09-29T05:24:39.706209+00:00 [scheduled]>[0m
[[34m2024-09-29T05:24:40.417+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG two_task_dag has 0/16 running and queued tasks[0m
[[34m2024-09-29T05:24:40.417+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: two_task_dag.bash_task_0 manual__2024-09-29T05:24:39.706209+00:00 [scheduled]>[0m
[[34m2024-09-29T05:24:40.419+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='two_task_dag', task_id='bash_task_0', run_id='manual__2024-09-29T05:24:39.706209+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-09-29T05:24:40.419+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'two_task_dag', 'bash_task_0', 'manual__2024-09-29T05:24:39.706209+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-09-29T05:24:40.478+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'two_task_dag', 'bash_task_0', 'manual__2024-09-29T05:24:39.706209+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-09-29T05:24:41.236+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/two_task_dag.py[0m
[[34m2024-09-29T05:24:41.754+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: two_task_dag.bash_task_0 manual__2024-09-29T05:24:39.706209+00:00 [queued]> on host codespaces-c567e2[0m
[[34m2024-09-29T05:24:42.747+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='two_task_dag', task_id='bash_task_0', run_id='manual__2024-09-29T05:24:39.706209+00:00', try_number=1, map_index=-1)[0m
[[34m2024-09-29T05:24:42.750+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=two_task_dag, task_id=bash_task_0, run_id=manual__2024-09-29T05:24:39.706209+00:00, map_index=-1, run_start_date=2024-09-29 05:24:41.845674+00:00, run_end_date=2024-09-29 05:24:42.297887+00:00, run_duration=0.452213, state=success, executor_state=success, try_number=1, max_tries=0, job_id=5, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-09-29 05:24:40.418358+00:00, queued_by_job_id=3, pid=35436[0m
[[34m2024-09-29T05:24:43.103+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: two_task_dag.bash_task_1 manual__2024-09-29T05:24:39.706209+00:00 [scheduled]>[0m
[[34m2024-09-29T05:24:43.103+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG two_task_dag has 0/16 running and queued tasks[0m
[[34m2024-09-29T05:24:43.103+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: two_task_dag.bash_task_1 manual__2024-09-29T05:24:39.706209+00:00 [scheduled]>[0m
[[34m2024-09-29T05:24:43.105+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='two_task_dag', task_id='bash_task_1', run_id='manual__2024-09-29T05:24:39.706209+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-09-29T05:24:43.105+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'two_task_dag', 'bash_task_1', 'manual__2024-09-29T05:24:39.706209+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-09-29T05:24:43.169+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'two_task_dag', 'bash_task_1', 'manual__2024-09-29T05:24:39.706209+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-09-29T05:24:43.984+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/two_task_dag.py[0m
[[34m2024-09-29T05:24:44.485+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: two_task_dag.bash_task_1 manual__2024-09-29T05:24:39.706209+00:00 [queued]> on host codespaces-c567e2[0m
[[34m2024-09-29T05:24:50.425+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='two_task_dag', task_id='bash_task_1', run_id='manual__2024-09-29T05:24:39.706209+00:00', try_number=1, map_index=-1)[0m
[[34m2024-09-29T05:24:50.428+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=two_task_dag, task_id=bash_task_1, run_id=manual__2024-09-29T05:24:39.706209+00:00, map_index=-1, run_start_date=2024-09-29 05:24:44.582386+00:00, run_end_date=2024-09-29 05:24:49.989504+00:00, run_duration=5.407118, state=success, executor_state=success, try_number=1, max_tries=0, job_id=6, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-09-29 05:24:43.104331+00:00, queued_by_job_id=3, pid=35455[0m
[[34m2024-09-29T05:24:50.511+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun two_task_dag @ 2024-09-29 05:24:39.706209+00:00: manual__2024-09-29T05:24:39.706209+00:00, state:running, queued_at: 2024-09-29 05:24:39.760714+00:00. externally triggered: True> successful[0m
[[34m2024-09-29T05:24:50.511+0000[0m] {[34mdagrun.py:[0m681} INFO[0m - DagRun Finished: dag_id=two_task_dag, execution_date=2024-09-29 05:24:39.706209+00:00, run_id=manual__2024-09-29T05:24:39.706209+00:00, run_start_date=2024-09-29 05:24:40.296047+00:00, run_end_date=2024-09-29 05:24:50.511688+00:00, run_duration=10.215641, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-09-29 05:24:39.706209+00:00, data_interval_end=2024-09-29 05:24:39.706209+00:00, dag_hash=a09d6de304709dd5ea129fc4a5b66bc1[0m
[[34m2024-09-29T05:25:29.587+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: two_task_dag.bash_task_0 manual__2024-09-29T05:25:28.285095+00:00 [scheduled]>[0m
[[34m2024-09-29T05:25:29.588+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG two_task_dag has 0/16 running and queued tasks[0m
[[34m2024-09-29T05:25:29.588+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: two_task_dag.bash_task_0 manual__2024-09-29T05:25:28.285095+00:00 [scheduled]>[0m
[[34m2024-09-29T05:25:29.589+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='two_task_dag', task_id='bash_task_0', run_id='manual__2024-09-29T05:25:28.285095+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-09-29T05:25:29.589+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'two_task_dag', 'bash_task_0', 'manual__2024-09-29T05:25:28.285095+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-09-29T05:25:29.653+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'two_task_dag', 'bash_task_0', 'manual__2024-09-29T05:25:28.285095+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-09-29T05:25:30.428+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/two_task_dag.py[0m
[[34m2024-09-29T05:25:30.869+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: two_task_dag.bash_task_0 manual__2024-09-29T05:25:28.285095+00:00 [queued]> on host codespaces-c567e2[0m
[[34m2024-09-29T05:25:31.781+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='two_task_dag', task_id='bash_task_0', run_id='manual__2024-09-29T05:25:28.285095+00:00', try_number=1, map_index=-1)[0m
[[34m2024-09-29T05:25:31.784+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=two_task_dag, task_id=bash_task_0, run_id=manual__2024-09-29T05:25:28.285095+00:00, map_index=-1, run_start_date=2024-09-29 05:25:30.959400+00:00, run_end_date=2024-09-29 05:25:31.336537+00:00, run_duration=0.377137, state=success, executor_state=success, try_number=1, max_tries=0, job_id=7, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-09-29 05:25:29.588674+00:00, queued_by_job_id=3, pid=35761[0m
[[34m2024-09-29T05:25:31.865+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: two_task_dag.bash_task_1 manual__2024-09-29T05:25:28.285095+00:00 [scheduled]>[0m
[[34m2024-09-29T05:25:31.865+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG two_task_dag has 0/16 running and queued tasks[0m
[[34m2024-09-29T05:25:31.865+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: two_task_dag.bash_task_1 manual__2024-09-29T05:25:28.285095+00:00 [scheduled]>[0m
[[34m2024-09-29T05:25:31.866+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='two_task_dag', task_id='bash_task_1', run_id='manual__2024-09-29T05:25:28.285095+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-09-29T05:25:31.867+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'two_task_dag', 'bash_task_1', 'manual__2024-09-29T05:25:28.285095+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-09-29T05:25:31.920+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'two_task_dag', 'bash_task_1', 'manual__2024-09-29T05:25:28.285095+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-09-29T05:25:32.804+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/two_task_dag.py[0m
[[34m2024-09-29T05:25:33.316+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: two_task_dag.bash_task_1 manual__2024-09-29T05:25:28.285095+00:00 [queued]> on host codespaces-c567e2[0m
[[34m2024-09-29T05:25:39.696+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='two_task_dag', task_id='bash_task_1', run_id='manual__2024-09-29T05:25:28.285095+00:00', try_number=1, map_index=-1)[0m
[[34m2024-09-29T05:25:39.754+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=two_task_dag, task_id=bash_task_1, run_id=manual__2024-09-29T05:25:28.285095+00:00, map_index=-1, run_start_date=2024-09-29 05:25:33.430602+00:00, run_end_date=2024-09-29 05:25:39.188778+00:00, run_duration=5.758176, state=success, executor_state=success, try_number=1, max_tries=0, job_id=8, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-09-29 05:25:31.865929+00:00, queued_by_job_id=3, pid=35779[0m
[[34m2024-09-29T05:25:41.334+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun two_task_dag @ 2024-09-29 05:25:28.285095+00:00: manual__2024-09-29T05:25:28.285095+00:00, state:running, queued_at: 2024-09-29 05:25:28.290792+00:00. externally triggered: True> successful[0m
[[34m2024-09-29T05:25:41.335+0000[0m] {[34mdagrun.py:[0m681} INFO[0m - DagRun Finished: dag_id=two_task_dag, execution_date=2024-09-29 05:25:28.285095+00:00, run_id=manual__2024-09-29T05:25:28.285095+00:00, run_start_date=2024-09-29 05:25:29.468103+00:00, run_end_date=2024-09-29 05:25:41.335312+00:00, run_duration=11.867209, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-09-29 05:25:28.285095+00:00, data_interval_end=2024-09-29 05:25:28.285095+00:00, dag_hash=a09d6de304709dd5ea129fc4a5b66bc1[0m
[[34m2024-09-29T05:27:03.902+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-09-29T05:32:03.930+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-09-29T05:37:03.969+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-09-29T05:42:04.008+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-09-29T05:47:04.039+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-09-29T05:52:04.064+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
